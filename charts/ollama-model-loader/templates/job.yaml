apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Release.Name }}-model-loader
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/name: ollama-model-loader
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/version: {{ .Chart.AppVersion | quote }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
  annotations:
    # Run this job in sync wave 1, after Ollama PVC is created (wave 0)
    argocd.argoproj.io/sync-wave: "1"
    # Force ArgoCD to replace the Job instead of updating it (Jobs are immutable)
    argocd.argoproj.io/sync-options: Replace=true
spec:
  backoffLimit: {{ .Values.job.backoffLimit }}
  ttlSecondsAfterFinished: {{ .Values.job.ttlSecondsAfterFinished }}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ollama-model-loader
        app.kubernetes.io/instance: {{ .Release.Name }}
    spec:
      {{- if .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml .Values.nodeSelector | nindent 8 }}
      {{- end }}
      {{- if .Values.tolerations }}
      tolerations:
        {{- toYaml .Values.tolerations | nindent 8 }}
      {{- end }}
      restartPolicy: {{ .Values.job.restartPolicy }}
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      containers:
        - name: model-loader
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          command:
            - /bin/sh
            - -c
            - |
              set -e
              
              echo "Starting Ollama model loader..."
              echo "Models to download: {{ join ", " .Values.models }}"
              
              # Start Ollama server in background
              echo "Starting Ollama server..."
              ollama serve &
              SERVER_PID=$!
              
              # Wait for server to be ready
              echo "Waiting for Ollama server to start..."
              sleep 5
              echo "✓ Ollama server should be ready!"
              
              # Download each model
              {{- range .Values.models }}
              echo "Downloading model: {{ . }}"
              if ollama pull {{ . }}; then
                echo "✓ Successfully downloaded: {{ . }}"
              else
                echo "✗ Failed to download: {{ . }}"
                # Continue with other models even if one fails
              fi
              {{- end }}
              
              # Stop server gracefully
              echo "Stopping Ollama server..."
              kill $SERVER_PID
              wait $SERVER_PID 2>/dev/null || true
              
              echo "✓ Model loading complete!"
          env:
            - name: OLLAMA_MODELS
              value: {{ .Values.persistence.mountPath }}
            - name: HOME
              value: /home/ollama
          volumeMounts:
            - name: models
              mountPath: {{ .Values.persistence.mountPath }}
          securityContext:
            {{- toYaml .Values.securityContext | nindent 12 }}
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
      volumes:
        - name: models
          persistentVolumeClaim:
            claimName: {{ .Values.persistence.existingClaim }}
